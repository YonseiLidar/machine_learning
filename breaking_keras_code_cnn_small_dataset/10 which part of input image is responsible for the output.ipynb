{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to run this block first time\n",
    "# However, don't need to run twice\n",
    "#\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "# # vgg = VGG16(weights='imagenet',\n",
    "# #             include_top=False,\n",
    "# #             input_shape=(150, 150, 3))\n",
    "# model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to run this block first time\n",
    "# However, don't need to run twice\n",
    "#\n",
    "# model.save('save/vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sungchullee/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/sungchullee/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sungchullee/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "tf.reset_default_graph()\n",
    "model = load_model('save/vgg.h5')\n",
    "x = model.input\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = tf.get_default_graph()\n",
    "# for op in g.get_operations():\n",
    "#     print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1000)\n",
      "()\n",
      "(?, 14, 14, 512)\n",
      "(?, 14, 14, 512)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "\n",
    "softmax = g.get_tensor_by_name('predictions/Softmax:0')\n",
    "print(softmax.shape)\n",
    "softmax_386_loss = tf.reduce_mean(softmax[:, 386]) #, axis=(0))\n",
    "print(softmax_386_loss.shape)\n",
    "block5_conv3 = g.get_tensor_by_name('block5_conv3/Relu:0')\n",
    "print(block5_conv3.shape)\n",
    "\n",
    "grads = tf.gradients(softmax_386_loss, block5_conv3)[0]\n",
    "print(grads.shape)\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "print(pooled_grads.shape)\n",
    "\n",
    "init = g.get_operation_by_name('init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "-103.939 143.061\n",
      "-116.779 138.22101\n",
      "-123.68 131.32\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = './downloads/creative_commons_elephant.jpg'\n",
    "\n",
    "# `img` is a PIL image of size 224x224\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# `img` is a float32 Numpy array of shape (224, 224, 3)\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "# We add a dimension to transform our array into a \"batch\"\n",
    "# of size (1, 224, 224, 3)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Finally we preprocess the batch\n",
    "# (this does channel-wise color normalization)\n",
    "img = preprocess_input(img)\n",
    "print(img.shape)\n",
    "print(img[0,:,:,0].min(), img[0,:,:,0].max())\n",
    "print(img[0,:,:,1].min(), img[0,:,:,1].max())\n",
    "print(img[0,:,:,2].min(), img[0,:,:,2].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sungchullee/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Predicted: [('n02504458', 'African_elephant', 0.909421), ('n01871265', 'tusker', 0.086182885), ('n02504013', 'Indian_elephant', 0.0043545826)]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(img)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    model.load_weights('save/vgg.h5')\n",
    "    \n",
    "    feed_dict = {x: img}\n",
    "    block5_conv3_run, pooled_grads_run = sess.run([block5_conv3, pooled_grads], feed_dict=feed_dict)\n",
    "\n",
    "# We multiply each channel in the feature map array\n",
    "# by \"how important this channel is\" with regard to the elephant class\n",
    "for i in range(512):\n",
    "    block5_conv3_run[:,:,:,i] *= pooled_grads_run[i]\n",
    "\n",
    "# The channel-wise mean of the resulting feature map\n",
    "# is our heatmap of class activation\n",
    "heatmap = np.mean(block5_conv3_run, axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPGElEQVR4nO3da4yc5XnG8eua2V3ba2xsQ4LApjFEhDaipESrCkKVVnEiUYIgUaqKqLRuieQvbUOiqAmID2nVL5USRYnUKpHFIahBRBUhDUIJxSWJokoJqjmIAiYxAYJNjG2Ky8Gn3dm5+2HHktl6drdzv/PMWs//J1m7Mzv33s8cfO37zrzv8zgiBKBerVEPAMBoEQJA5QgBoHKEAFA5QgCoHCEAVG5ZhIDtq2z/3PZztm8u3Pt82z+yvcv207ZvKtn/pHG0bT9u+4ER9F5n+17bz/YehysK9/9s77F/yvY9tlcOud8dtg/Yfuqk6zbY3mF7d+/r+sL9v9R7/J+0/V3b64bVf76Rh4DttqR/kvSHkt4r6ZO231twCB1Jn4uI35J0uaS/LNz/hJsk7RpBX0n6mqQHI+I3Jb2v5Dhsb5T0aUlTEXGJpLak64fc9puSrpp33c2SHo6IiyQ93Ltcsv8OSZdExKWSfiHpliH2f5uRh4Ck35X0XEQ8HxHTkr4t6bpSzSNiX0Q81vv+Tc39B9hYqr8k2d4k6aOSbivZt9d7raQPSrpdkiJiOiL+p/AwxiStsj0maVLSr4fZLCJ+Ium1eVdfJ+mu3vd3SfpYyf4R8VBEdHoXfyZp07D6z7ccQmCjpD0nXd6rwv8JT7C9WdJlkh4p3Pqrkj4vqVu4ryRdKOmgpDt7uyO32V5dqnlEvCzpy5JekrRP0usR8VCp/ic5JyL29ca0T9I7RzCGE26U9INSzZZDCPgU1xU/ltn2GZK+I+kzEfFGwb7XSDoQEY+W6jnPmKT3S/p6RFwm6bCGuyn8Nr197+skXSDpPEmrbd9Qqv9yY/tWze2i3l2q53IIgb2Szj/p8iYNeXNwPtvjmguAuyPivpK9JV0p6VrbL2puV+hDtr9VsP9eSXsj4sTWz72aC4VSPizphYg4GBEzku6T9IGC/U/Yb/tcSep9PVB6ALa3SrpG0p9EwZN6lkMI/Keki2xfYHtCc28K3V+quW1rbn94V0R8pVTfEyLilojYFBGbNXfffxgRxf4SRsQrkvbYvrh31RZJz5Tqr7ndgMttT/aeiy0azRuk90va2vt+q6TvlWxu+ypJX5B0bUQcKdlbETHyf5Ku1tw7or+UdGvh3r+nud2PJyU90ft39Ygehz+Q9MAI+v6OpJ29x+BfJa0v3P/vJD0r6SlJ/yxpxZD73aO59x9mNLcl9ClJZ2nuU4Hdva8bCvd/TnPvjZ14DX6j1OPv3qAAVGo57A4AGCFCAKgcIQBUjhAAKkcIAJVbViFgexv96+xf830fdf9lFQKSRvpE0H+k/Wu+7yPtv9xCAEBhRQ8WmmitjFWtNX1/Ph3HNLHQfBLZsbYWzrzp7lFNtFbleixkkfEvdv9jdrbpEb3NjI5rXCv6/tyLPH6LavevX9Jjn32pLvD4T8dRTXiIz7106lPlTvTvHtNEa5G5VNrtgVsfnXlD07NHTjmCsYF/6wBWtdboijM/PnB9HD+e6u/Vxc6QPbVOZ/HbLGD20KGGBjKY1mTu8Wut7f8HYCmimzzTOvn6kZMh2FogBZZiw+CTDf30V3f1/Rm7A0DlCAGgcqkQGOUEoQCaMXAILIMJQgE0ILMlMNIJQgE0IxMCy2aCUACDy3xEuKQJQnuHQ26TpJWtMxLtAAxDZktgSROERsT2iJiKiKkFDwQCMBKZEBjpBKEAmjHw7kBEdGz/laR/09zSUXdExNONjQxAEanDhiPi+5K+39BYAIwARwwClSMEgMoVPYtQEakzAbtHcguzeHo6VZ8+lTd5KnRrcjJVn338uocPj7S+vXZtql4T47n66ZlUeXRyz7/3vzp48QJnsLIlAFSOEAAqRwgAlSMEgMoRAkDlCAGgcoQAUDlCAKgcIQBUjhAAKkcIAJUjBIDKEQJA5QgBoHKEAFC5svMJtNtqrR98ZdXM0sySpOx8AMl6J8efnk9hLPd0z17526n6iT25VZU7Z+dWNW4fys1noLHc89c6mlsVOcYTz9+x/rVsCQCVIwSAyhECQOUIAaBymaXJz7f9I9u7bD9t+6YmBwagjMzbxR1Jn4uIx2yvkfSo7R0R8UxDYwNQwMBbAhGxLyIe633/pqRdYmly4LTTyHsCtjdLukzSI038PgDlpA8Wsn2GpO9I+kxEvHGKn2+TtE2SVrZzB3sAaF5qS8D2uOYC4O6IuO9Ut4mI7RExFRFTE61VmXYAhiDz6YAl3S5pV0R8pbkhASgpsyVwpaQ/lfQh20/0/l3d0LgAFDLwewIR8R+S3OBYAIwARwwClSMEgMqVnU+gZWnFxMDlbucyq3sseT53J7c+vVflPh3x+OCPnSS1Nm9K1R8+K9ffncRcEpLGf7kvVd/ZfyBVP7bxvFR9d0PuI/Lu5OCPf7zcfy4EtgSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlSMEgMoRAkDlCAGgcoQAUDlCAKgcIQBUjhAAKld2PoGQFFG05cmcWd9dUuvM3Pngxy/dnKo/+o7xVP3MZG42uNfel3vuumf2P6d9KVa+8O5U/aoDF6bqnXzprts9naqfXTH43+xo93/u2RIAKkcIAJUjBIDKEQJA5dIhYLtt+3HbDzQxIABlNbElcJPmliUHcBrKLki6SdJHJd3WzHAAlJbdEviqpM9L6jYwFgAjkFmV+BpJByLi0UVut832Tts7p7tHBm0HYEiyqxJfa/tFSd/W3OrE35p/o4jYHhFTETE10ZpMtAMwDAOHQETcEhGbImKzpOsl/TAibmhsZACK4DgBoHKNnEAUET+W9OMmfheAstgSACpHCACVKzufwMyMuvv2D1zu1blPF7z5nFT9nmvOTtW/dXHufPLx1bmPWLsvJz+dSZ5P77dyL7eZNbkBeDY3n8LZT3dS9eOHjuXqF5gTYDHu9D+Uhy0BoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlSMEgMoVnU8gItQ9ljin+vjxVH//xrmp+r+58V9S9X+29tVU/R8/vyVV/+KD70nVr3gjt7xEZ2XufP41L+bmUxg7lKufXbMyVe/Z2VR967XDg/fu9O/NlgBQOUIAqBwhAFSOEAAql12VeJ3te20/a3uX7SuaGhiAMrKfDnxN0oMR8Ue2JySx2CBwmhk4BGyvlfRBSX8uSRExLSk3pzaA4jK7AxdKOijpTtuP277N9uqGxgWgkEwIjEl6v6SvR8Rlkg5Lunn+jWxvs73T9s4Z5Q72AdC8TAjslbQ3Ih7pXb5Xc6HwNhGxPSKmImJqXCsS7QAMw8AhEBGvSNpj++LeVVskPdPIqAAUk/104K8l3d37ZOB5SX+RHxKAklIhEBFPSJpqaCwARoAjBoHKEQJA5YrOJ5DVmswdkNh69fVU/d/++ydS9X+/IfcR6ezB3Pns6ydS5Rp/K3c+fLidqh/b/etUvWZyx7K12rn5KLpn5J6A1ptHE9X953JgSwCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlSMEgMoRAkDlCAGgcqfVfALdw4Ovzy5J3SO59enfc+eZqfo3370mVd9NPlvuRqq+syr3N2PNz3PzOcSxY6n67uHc899+5WCqfmzNGan6GE+8AMx8AgD6IASAyhECQOUIAaByqRCw/VnbT9t+yvY9tnMzYQIobuAQsL1R0qclTUXEJZLakq5vamAAysjuDoxJWmV7TNKkpOSc0ABKyyxI+rKkL0t6SdI+Sa9HxENNDQxAGZndgfWSrpN0gaTzJK22fcMpbrfN9k7bO2eUW3wDQPMyuwMflvRCRByMiBlJ90n6wPwbRcT2iJiKiKlxrUi0AzAMmRB4SdLltidtW9IWSbuaGRaAUjLvCTwi6V5Jj0n6r97v2t7QuAAUkjolJSK+KOmLDY0FwAhwxCBQOUIAqNxpNZ9AWuTOp4/HnknVrzv0rlT99Mb1qfoY639O+VJM7H8r1//5l1L13eR8Almzr/537hdk6xMi+n88z5YAUDlCAKgcIQBUjhAAKkcIAJUjBIDKEQJA5QgBoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOXqmk8gKzkfQef5F1P17T3JtV2imyqf7XRy/bEssSUAVI4QACpHCACVIwSAyi0aArbvsH3A9lMnXbfB9g7bu3tfczNgAhiZpWwJfFPSVfOuu1nSwxFxkaSHe5cBnIYWDYGI+Imk1+ZdfZ2ku3rf3yXpYw2PC0Ahg74ncE5E7JOk3td3NjckACUN/WAh29skbZOklZocdjsA/0+Dbgnst32uJPW+Huh3w4jYHhFTETE1rhUDtgMwLIOGwP2Stva+3yrpe80MB0BpS/mI8B5JP5V0se29tj8l6R8kfcT2bkkf6V0GcBpa9D2BiPhknx9taXgsAEaAIwaByhECQOVOr/kE7Fz52HiqPmamU/VZo+6PEcu8/heYCoMtAaByhABQOUIAqBwhAFSOEAAqRwgAlSMEgMoRAkDlCAGgcoQAUDlCAKgcIQBUjhAAKkcIAJUjBIDKlZ1PwJbHJwYuj9nZVPts/Wmv1U6Vu52rV3ST5QucFF9A9v5nX3+p/jP95yJgSwCoHCEAVI4QACo36NLkX7L9rO0nbX/X9rrhDhPAsAy6NPkOSZdExKWSfiHplobHBaCQgZYmj4iHIqLTu/gzSZuGMDYABTTxnsCNkn7QwO8BMAKp4wRs3yqpI+nuBW7D0uTAMjZwCNjeKukaSVsiou9RHBGxXdJ2SVrbOmu0R3sA+D8GCgHbV0n6gqTfj4gjzQ4JQEmDLk3+j5LWSNph+wnb3xjyOAEMyaBLk98+hLEAGAGOGAQqRwgAlSMEgMqVnU8gQjEzXbQlTtJNzseQrB859z+nfimik5sPQf0/SV9aeebxX6A3WwJA5QgBoHKEAFA5QgCoHCEAVI4QACpHCACVIwSAyhECQOUIAaByhABQOUIAqBwhAFSOEAAqRwgAlfMCs4U338w+KOlXC9zkbEmvFhoO/ZdX/5rve4n+74qId5zqB0VDYDG2d0bEFP3r61/zfR91f3YHgMoRAkDlllsIbKd/tf1rvu8j7b+s3hMAUN5y2xIAUBghAFSOEAAqRwgAlSMEgMr9L3fEY+fgAH1tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# We use cv2 to load the original image\n",
    "img_original = cv2.imread(img_path)\n",
    "\n",
    "# We resize the heatmap to have the same size as the original image\n",
    "heatmap = cv2.resize(heatmap, (img_original.shape[1], img_original.shape[0]))\n",
    "\n",
    "# We convert the heatmap to RGB\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "# We apply the heatmap to the original image\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "# 0.4 here is a heatmap intensity factor\n",
    "superimposed_img = heatmap * 0.4 + img_original\n",
    "\n",
    "# Save the image to disk\n",
    "cv2.imwrite('./downloads/elephant_cam.jpg', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
